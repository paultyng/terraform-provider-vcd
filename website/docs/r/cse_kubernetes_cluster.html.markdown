---
layout: "vcd"
page_title: "VMware Cloud Director: vcd_cse_kubernetes_cluster"
sidebar_current: "docs-vcd-resource-cse-kubernetes-cluster"
description: |-
  Provides a resource to manage Kubernetes clusters in VMware Cloud Director with Container Service Extension installed and running.
---

# vcd\_cse\_kubernetes\_cluster

Provides a resource to manage Kubernetes clusters in VMware Cloud Director with Container Service Extension (CSE) installed and running.

Supported in provider *v3.12+*

-> To install CSE in VMware Cloud Director, please follow [this guide](/providers/vmware/vcd/latest/docs/guides/container_service_extension_4_x_install)

## Example Usage

```hcl
data "vcd_catalog" "tkg_catalog" {
  org  = "solutions_org" # The catalog is shared with 'tenant_org', so it is visible for tenants
  name = "tkgm_catalog"
}

# Fetch a valid Kubernetes template OVA
data "vcd_catalog_vapp_template" "tkg_ova" {
  org        = data.vcd_catalog.tkg_catalog.org
  catalog_id = data.vcd_catalog.tkg_catalog.id
  name       = "ubuntu-2004-kube-v1.25.7+vmware.2-tkg.1-8a74b9f12e488c54605b3537acb683bc"
}

data "vcd_org_vdc" "vdc" {
  org  = "tenant_org"
  name = "tenant_vdc"
}

data "vcd_nsxt_edgegateway" "egw" {
  org      = data.vcd_org_vdc.vdc.org
  owner_id = data.vcd_org_vdc.vdc.id
  name     = "tenant_edgegateway"
}

data "vcd_network_routed_v2" "routed" {
  org             = data.vcd_nsxt_edgegateway.egw.org
  edge_gateway_id = data.vcd_nsxt_edgegateway.egw.id
  name            = "tenant_net_routed"
}

# Fetch a valid Sizing policy created during CSE installation.
# Refer to the CSE installation guide for more information.
data "vcd_vm_sizing_policy" "tkg_small" {
  name = "TKG small"
}

data "vcd_storage_profile" "sp" {
  org  = data.vcd_org_vdc.vdc.org
  vdc  = data.vcd_org_vdc.vdc.name
  name = "*"
}

# The token file is required, and it should be safely stored
resource "vcd_api_token" "token" {
  name             = "myClusterToken"
  file_name        = "/home/Bob/vcdTestAccVcdCseKubernetesCluster.json"
  allow_token_file = true
}

resource "vcd_cse_kubernetes_cluster" "my_cluster" {
  cse_version        = "4.2"
  runtime            = "tkg"
  name               = "my-cluster"
  ova_id             = data.vcd_catalog_vapp_template.tkg_ova.id
  org                = data.vcd_org_vdc.vdc.org
  vdc_id             = data.vcd_org_vdc.vdc.id
  network_id         = data.vcd_network_routed_v2.routed.id
  api_token_file	 = vcd_api_token.token.file_name

  control_plane {
    machine_count      = 1
    disk_size_gi       = 20
    sizing_policy_id   = data.vcd_vm_sizing_policy.tkg_small.id
    storage_profile_id = data.vcd_storage_profile.sp.id
  }

  node_pool {
    name               = "node-pool-1"
    machine_count      = 1
    disk_size_gi       = 20
    sizing_policy_id   = data.vcd_vm_sizing_policy.tkg_small.id
    storage_profile_id = data.vcd_storage_profile.sp.id
  }

  node_pool {
    name               = "node-pool-2"
    machine_count      = 1
    disk_size_gi       = 20
    sizing_policy_id   = data.vcd_vm_sizing_policy.tkg_small.id
    storage_profile_id = data.vcd_storage_profile.sp.id
  }

  default_storage_class {
    name               = "sc-1"
    storage_profile_id = data.vcd_storage_profile.sp.id
    reclaim_policy     = "delete"
    filesystem         = "ext4"
  }

  pods_cidr     = "100.10.0.0/11"
  services_cidr = "100.90.0.0/11"

  auto_repair_on_errors = false
  node_health_check     = false
}

```

## Argument Reference

The following arguments are supported:

* `cse_version` - (Required) Specifies the CSE version to use. Only `4.2` is supported
* `runtime` - (Optional) Specifies the Kubernetes runtime to use. Defaults to `tkg` (Tanzu Kubernetes Grid)
* `name` - (Required) The name of the Kubernetes cluster. It must contain only lowercase alphanumeric characters or "-", 
  start with an alphabetic character, end with an alphanumeric, and contain at most 31 characters
* `ova_id` - (Required) The ID of the vApp Template that corresponds to a Kubernetes template OVA
* `org` - (Optional) The name of organization that will host the Kubernetes cluster, optional if defined in the provider configuration
* `vdc_id` - (Required) The ID of the VDC that hosts the Kubernetes cluster
* `network_id` - (Required) The ID of the network that the Kubernetes cluster will use
* `owner` - (Optional) The user that creates the cluster and owns the API token specified in `api_token`.
  It must have the `Kubernetes Cluster Author` role that was created during CSE installation.
  If not specified, it assumes it's the user from the provider configuration
* `api_token_file` - (Required) A file generated by [`vcd_api_token` resource](/providers/vmware/vcd/latest/docs/resources/api_token),
  that stores the API token used to create and manage the cluster, owned by the user specified in `owner`.
  Be careful about this file, as it contains sensitive information
* `ssh_public_key` - (Optional) The SSH public key used to login into the cluster nodes
* `control_plane` - (Required) See [**Control Plane**](#control-plane)
* `node_pool` - (Required) See [**Node Pools**](#node-pools)
* `default_storage_class` - (Optional) See [**Default Storage Class**](#default-storage-class)
* `pods_cidr` - (Optional) A CIDR block for the pods to use. Defaults to `100.96.0.0/11`
* `services_cidr` - (Optional) A CIDR block for the services to use. Defaults to `100.64.0.0/13`
* `virtual_ip_subnet` - (Optional) A virtual IP subnet for the cluster
* `auto_repair_on_errors` - (Optional) If errors occur before the Kubernetes cluster becomes available, and this argument is `true`,
  CSE Server will automatically attempt to repair the cluster. Defaults to `false`
* `node_health_check` - (Optional) After the Kubernetes cluster becomes available, nodes that become unhealthy will be
  remediated according to unhealthy node conditions and remediation rules. Defaults to `false`
* `operations_timeout_minutes` - (Optional) The time, in minutes, to wait for the cluster operations to be successfully completed.
  For example, during cluster creation/update, it should be in `provisioned` state before the timeout is reached, otherwise the
  operation will return an error. For cluster deletion, this timeout specifies the time to wait until the cluster is completely deleted.
  Setting this argument to `0` means to wait indefinitely (not recommended as it could hang Terraform if the cluster can't be created or deleted
  due to a configuration error). Defaults to `60`

### Control Plane

The `control_plane` block is **required** and unique per resource, meaning that there must be **exactly one** of these
in every resource.

This block asks for the following arguments:

* `machine_count` - (Optional) The number of nodes that the control plane has. Must be an odd number and higher than `0`. Defaults to `3`
* `disk_size_gi` - (Optional) Disk size, in **Gibibytes (Gi)**, for the control plane VMs. Must be at least `20`. Defaults to `20`
* `sizing_policy_id` - (Optional) VM Sizing policy for the control plane VMs. Must be one of the ones made available during CSE installation
* `placement_policy_id` - (Optional) VM Placement policy for the control plane VMs
* `storage_profile_id` - (Optional) Storage profile for the control plane VMs
* `ip` - (Optional) IP for the control plane. It will be automatically assigned during cluster creation if left empty

### Node Pools

The `node_pool` block is **required**, and every cluster should have **at least one** of them.

Each block asks for the following arguments:

* `name` - (Required) The name of the node pool. It must contain only lowercase alphanumeric characters or "-",
  start with an alphabetic character, end with an alphanumeric, and contain at most 31 characters
* `machine_count` - (Optional) The number of VMs that the node pool has. Must be higher than `0`. Defaults to `1`
* `disk_size_gi` - (Optional) Disk size, in **Gibibytes (Gi)**, for the node pool VMs. Must be at least `20`. Defaults to `20`
* `sizing_policy_id` - (Optional) VM Sizing policy for the control plane VMs. Must be one of the ones made available during CSE installation
* `placement_policy_id` - (Optional) VM Placement policy for the node pool VMs. If this one is set, `vgpu_policy_id` must be empty
* `vgpu_policy_id` - (Optional) vGPU policy for the node pool VMs. If this one is set, `placement_policy_id` must be empty
* `storage_profile_id` - (Optional) Storage profile for the node pool VMs

### Default Storage Class

The `default_storage_class` block is **optional**, and every cluster should have **at most one** of them.

If defined, the block asks for the following arguments:

* `name` - (Required) The name of the default storage class. It must contain only lowercase alphanumeric characters or "-",
  start with an alphabetic character, end with an alphanumeric, and contain at most 31 characters
* `storage_profile_id` - (Required) Storage profile for the default storage class
* `reclaim_policy` - (Required) A value of `delete` deletes the volume when the PersistentVolumeClaim is deleted. `retain` does not,
  and the volume can be manually reclaimed
* `filesystem` - (Required) Filesystem of the storage class, can be either `ext4` or `xfs`

## Attribute Reference

The following attributes are available for consumption as read-only attributes:

* `kubernetes_version` - The version of Kubernetes installed in this cluster
* `tkg_product_version` - The version of TKG installed in this cluster
* `capvcd_version` - The version of CAPVCD used by this cluster
* `cluster_resource_set_bindings` - The cluster resource set bindings of this cluster
* `cpi_version` - The version of the Cloud Provider Interface used by this cluster
* `csi_version` - The version of the Container Storage Interface used by this cluster
* `state` - The Kubernetes cluster status, can be `provisioning` when it is being created, `provisioned` when it was successfully
  created and ready to use, or `error` when an error occurred. `provisioning` can only be obtained when a timeout happens during
  cluster creation. `error` can only be obtained either with a timeout or when `auto_repair_on_errors=false`.
* `kubeconfig` - The ready-to-use Kubeconfig file **contents** as a raw string. Only available when `state=provisioned`
* `persistent_volumes` - A set of persistent volumes that are present in the cluster, only available when a `default_storage_class` was provided during
  cluster creation:
  * `name` - The name of the persistent volume
  * `status` - The status of the persistent volume
  * `shared` - Whether the persistent volume is shared or not
  * `attached_node_count` - How many nodes are consuming the persistent volume
  * `iops` - I/O operations per second for the persistent volume
  * `size` - Size of the persistent volume
  * `storage_profile` - Storage profile name of the persistent volume
  * `owner` - Owner of the persistent volume

## Updating

Only the following arguments can be updated:

* `ova_id`: The cluster must allow upgrading to the new TKG version
* `machine_count` of the `control_plane`: Supports scaling up and down
* `machine_count` of any `node_pool`: Supports scaling up and down
* `auto_repair_on_errors`
* `node_health_check`
* `operations_timeout_minutes`: Does not require modifying the existing cluster

Updating any other argument will delete the existing cluster and create a new one, if the Terraform plan is applied.

Upgrading CSE version with `cse_version` is not supported as this operation would require human intervention,
as stated [in the official documentation](https://docs.vmware.com/en/VMware-Cloud-Director-Container-Service-Extension/4.1/VMware-Cloud-Director-Container-Service-Extension-Using-Tenant-4.1/GUID-092C40B4-D0BA-4B90-813F-D36929F2F395.html).

## Importing

!!!!!!!!!!! TODO: NOT IMPLEMENTED. HOW TO DEAL WITH REQUIRED IDS?

~> The current implementation of Terraform import can only import resources into the state.
It does not generate configuration. [More information.](https://www.terraform.io/docs/import/)

An existing Kubernetes cluster can be [imported][docs-import] into this resource via supplying the Cluster (RDE) ID for it.
An example is below:

```hcl
# This is just a snippet of code that will host the imported cluster from VCD.
# This must not be created with Terraform beforehand
resource "vcd_cse_kubernetes_cluster" "imported_cluster" {
  # Only the required arguments are needed
  cse_version        = "4.2"
  name               = "my-cluster"
  ova_id             = data.vcd_catalog_vapp_template.tkg_ova.id
  org                = "tenant_org"
  vdc_id             = data.vcd_org_vdc.vdc.id
  network_id         = data.vcd_network_routed_v2.routed.id
  api_token_file	 = vcd_api_token.token.file_name

  control_plane {
  
  }

  node_pool {
    name               = "node-pool-1"
  }
}
```

```sh
terraform import vcd_cse_kubernetes_cluster.imported_cluster urn:vcloud:entity:vmware:capvcdCluster:1d24af33-6e5a-4d47-a6ea-06d76f3ee5c9
```

-> The ID is required as it is the only way to unequivocally identify a Kubernetes cluster inside VCD. To obtain the ID
you can check the Kubernetes Container Clusters UI plugin, where all the available clusters are listed.

After that, you can expand the configuration file and either update or delete the Kubernetes cluster. Running `terraform plan`
at this stage will show the difference between the minimal configuration file and the Kubernetes cluster stored properties.

[docs-import]:https://www.terraform.io/docs/import/
